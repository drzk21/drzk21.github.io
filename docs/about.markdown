---
layout: page
title: About
permalink: /about/
---
We hear a lot about the potential risks of Artificial General Intelligence (AGI), but little about what the world would look like should we manage to avoid these risks. For some, this isn’t a matter of concern–as long as we avoid a large-scale catastrophe, we’ll be fine. The transformative nature of AGI, however, may warrant more caution. Just because we avoid a horrific outcome does not mean that we have a world that promotes human (and perhaps other species) flourishing. I believe that we need to start thinking about what a post-AGI world may look like, so that we can make wise decisions about our future.

There isn’t much written on post-AGI issues, likely because any such work would be quite speculative at this point. That being said, no one truly knows how soon we may need to grapple with these issues. I feel this fact alone makes this work worth exploring, and that is what I want to do here. To start, I’m simply going to post my own thoughts and questions on post-AGI considerations. I hope that this work can help others start conversations, find research directions, and more.

<!-- This is the base Jekyll theme. You can find out more info about customizing your Jekyll theme, as well as basic Jekyll usage documentation at [jekyllrb.com](https://jekyllrb.com/)

You can find the source code for Minima at GitHub:
[jekyll][jekyll-organization] /
[minima](https://github.com/jekyll/minima)

You can find the source code for Jekyll at GitHub:
[jekyll][jekyll-organization] /
[jekyll](https://github.com/jekyll/jekyll) -->


[jekyll-organization]: https://github.com/jekyll
